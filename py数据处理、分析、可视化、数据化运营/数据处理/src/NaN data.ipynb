{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值从哪里来：\n",
    "1. 包含缺失值的数据值\n",
    "\n",
    "2. 整理数据过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在read_csv中有三个参数与与缺失值有关：\n",
    "1. na_values\n",
    "2. keep_default_na\n",
    "3. na_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "#数据包含nan\n",
    "visiter_file = \"../data/survey_visited.csv\"\n",
    "print(pd.read_csv(visiter_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3            \n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(visiter_file,keep_default_na=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(visiter_file,\n",
    "                  na_values=[\"\"],\n",
    "                  keep_default_na=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先下载raw_data_urls.txt中的数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "..\\data\\fhv_tripdata_2015-01.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-02.csv\n",
      "\n",
      "..\\data\\fhv_tripdata_2015-02.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-03.csv\n",
      "\n",
      "..\\data\\fhv_tripdata_2015-03.csv\n"
     ]
    }
   ],
   "source": [
    "with open('../data/raw_data_urls.txt','r') as data_urls:\n",
    "    for line ,url in enumerate(data_urls):\n",
    "        if line == 3:\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join(\"..\",'data',fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data\\\\fhv_tripdata_2015-01.csv', '../data\\\\fhv_tripdata_2015-02.csv', '../data\\\\fhv_tripdata_2015-03.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "nyc_taxi_data = glob.glob(\"../data/fhv_*\")\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "2               B00013  2015-01-01 01:23:00         NaN\n",
      "3               B00013  2015-01-01 01:44:00         NaN\n",
      "4               B00013  2015-01-01 02:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n",
      "2               B00013  2015-02-01 00:21:00         NaN\n",
      "3               B00013  2015-02-01 01:00:00         NaN\n",
      "4               B00013  2015-02-01 02:10:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "2               B00029  2015-03-01 00:11:00         3.0\n",
      "3               B00029  2015-03-01 00:11:00       259.0\n",
      "4               B00029  2015-03-01 00:13:00       174.0\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.head(5))\n",
    "print(taxi2.head(5))\n",
    "print(taxi3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2746033, 3)\n",
      "(3126401, 3)\n",
      "(3281427, 3)\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9153861, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi = pd.concat([taxi1,taxi2,taxi3])\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\\fhv_tripdata_2015-01.csv\n",
      "../data\\fhv_tripdata_2015-02.csv\n",
      "../data\\fhv_tripdata_2015-03.csv\n",
      "(9153861, 3)\n"
     ]
    }
   ],
   "source": [
    "#当数据分成很多部分是，手动保存每个DataFrame会很繁琐，\n",
    "#可以使用循环和列表推导\n",
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    print(csv_filename)\n",
    "    \n",
    "    df = pd.read_csv(csv_filename)\n",
    "    \n",
    "    list_taxi_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "2               B00013  2015-01-01 01:23:00         NaN\n",
      "3               B00013  2015-01-01 01:44:00         NaN\n",
      "4               B00013  2015-01-01 02:00:00         NaN\n",
      "(9153861, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(list_taxi_df))\n",
    "print(type(list_taxi_df[0]))\n",
    "print(list_taxi_df[0].head())\n",
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#列表推导式\n",
    "list_taxi_df_comp = [pd.read_csv(data) for data in nyc_taxi_data]\n",
    "taxi_loop_concat_comp = pd.concat(list_taxi_df_comp)\n",
    "print(taxi_loop_concat_comp.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
