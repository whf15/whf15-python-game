{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Center><font color=red><b>考试题</b></font></Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注：先将试卷下载到本地,做完后进行上传,谢谢！\n",
    "* 试卷命名格式: Exam_学号.ipynb  例如：Exam_123456.ipynb\n",
    "* 试卷上传地址(请将自己的试卷存放到该地址)：http://47.93.208.249:9320/tree/0.Teacher/Online/Exam_students\n",
    "* 发布的试卷是只读模式，请下载或移动到上述地址后作答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学号(双击填写): 576123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 简答题(4分/题 共100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.简述线性分类器的原理."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    线性分类器是利用线性函数:\n",
    "               y = wx + b\n",
    "    对于给定的训练集,训练出合适的参数W和b（W和b是训练的产物）,\n",
    "    使得分类器的预测结果尽可能接近于真实类（真实类的得分越高越好，其他类的得分越低越好）。\n",
    "    用loss function来衡量参数的好坏，训练的过程就是通过调整参数来减小loss的过程。\n",
    "    训练就是为每个类寻找一个决策边界，决策边界能将属于这类的样本分到界限的一边(得分大于0)\n",
    "    其它样本分到界限的另一边(得分小于0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.物体检测问题概述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "判断一幅图像上是否存在感兴趣的物体，如果存在，就给出所有感兴趣物体的类别和位置.\n",
    "物体检测是用矩形框框出物体位置,实例分割是可以更加精准框出图像，可以框出物体轮廓."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.计算机视觉中，有哪几种基本任务？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1、分类\n",
    "\n",
    "给定一张输入图像，图像分类任务旨在判断该图像所属类别。\n",
    "2、定位\n",
    "\n",
    "在图像分类的基础上，我们还想知道图像中的目标具体在图像的什么位置，通常是以包围盒的(bounding box)形式。\n",
    "3、检测\n",
    "\n",
    "在目标定位中，通常只有一个或固定数目的目标，而目标检测更一般化，其图像中出现的目标种类和数目都不定。因此，目标检测是比目标定位更具挑战性的任务。\n",
    "\n",
    "4.语义分割：\n",
    "\n",
    "语义分割是目标检测更进阶的任务，目标检测只需要框出每个目标的包围盒，语义分割需要进一步判断图像中哪些像素属于哪个目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.常见物体检测算法列举"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. R-CNN\n",
    "2. Faster R-CNN\n",
    "3. SSD \n",
    "4. YOLO\n",
    "5. DPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.针对如下图片,我们需要调节哪些参数?为什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center class=\"half\">       \n",
    "    <img src=\"https://s3.ax1x.com/2021/01/21/shHjdx.jpg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 调小学习率: 因为损失函数的曲线变化不收敛,所以降低学习速率.\n",
    "2. 增加数据集的数量, 因为训练数据的学习效果不是好.\n",
    "3. 增加batchSize的数量, 因为训练数据的准确率比较低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.写出神经网络中常见的激励函数(至少三个)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  (1)sigmoid:\n",
    "      f(z)=1/(1+e(−z))\n",
    " \n",
    "      f′(z)=f(z)[1−f(z)]\n",
    "    \n",
    " (2)Tanh: \n",
    "      f(z)= tanh(z)\n",
    " \n",
    "      f′(z)=1−[f(z)]2\n",
    " (3) Relu:\n",
    "     f′(z)=  0,z<01,\n",
    "             1,z>0\n",
    "             undefind,z=0\n",
    "                \n",
    "  (4) f(x)=  x  x ≥ 0\n",
    "             0.1*x  x<0\n",
    " \n",
    "      ∂f(x)/∂x =  1   x ≥ 0\n",
    "                 0.1  x<0             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.请问图示中卷积模板功能?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center class=\"half\">       \n",
    "    <img src=\"https://s3.ax1x.com/2021/01/21/shbNfU.jpg\" width=\"40%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "边缘检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、计算题(提示:参数共享，不考虑bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T06:36:15.614551Z",
     "start_time": "2019-10-08T06:36:15.609786Z"
    }
   },
   "source": [
    "* Example1: 200\\*200 image(灰度图), 40K hidden units  有多少个参数?\n",
    "* Example2: 200\\*200 image(灰度图), 40K hidden units, Filter size: 10\\*10 有多少个参数?\n",
    "* Example3: 200\\*200 image(灰度图), 100 Filter, Filter size:10\\*10  有多少参数?\n",
    "* Example4: 图像尺寸为[32\\*32\\*3], 卷积窗口大小为5\\*5, 卷积模板个数为1, 有多少参数?\n",
    "* Example5: 图像尺寸为[16\\*16\\*20], 卷积窗口大小为3\\*3, 卷积模板个数为10, 有多少参数?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200*200 image(灰度图), 40K hidden units 有个40000 * 40000 = 16 0000 0000个参数\n",
    "200*200 image(灰度图), 40K hidden units, Filter size: 10*10 有40000 * 10 * 10 = 4 00 0000个个参数\n",
    "200*200 image(灰度图), 100 Filter, Filter size:10*10  有00 * 10 * 10 = 1 00 00个参数\n",
    "图像尺寸为[32*32*3], 卷积窗口大小为5*5, 卷积模板个数为1, 有5参5 * 5 * 3 = 75个参数\n",
    "图像尺寸为[16*16*20], 卷积窗口大小为3*3, 卷积模板个数为10, 有参数 3 * 3 * 20 * 10 = 1800个参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.计算下图池化层(MaxPoolling)结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center class=\"half\">       \n",
    "    <img src=\"https://s3.ax1x.com/2021/01/21/shq9A0.jpg\" width=\"80%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[6,8],\n",
    " [3,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.什么是感受野?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "感受野每一层输出的特征图(feature map)上的像素点在原始图像上映射的区域大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.简述Encode和Decode思想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder-Decoder框架有一个最显著的特征就是它是一个End-to-End学习的算法,这样的模型往往用在机器翻译中，比如将法语翻译成英语。\n",
    "这样的模型也被叫做 Sequence to Sequence learning。\n",
    "所谓编码，就是将输入序列转化成一个固定长度的向量；解码，就是将之前生成的固定向量再转化成输出序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.什么是NMS（Non-maximum suppression 非极大值抑制）?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "非极大值抑制，其思想是搜素局部最大值，抑制极大值。目标检测的过程中在同一目标的位置上会产生大量的候选框，\n",
    "这些候选框相互之间可能会有重叠，此时我们需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.什么是Hard Mining？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hard Mining是深度学习中难分样本的挖掘.主要是思想是如何将难分样本抽取出来，\n",
    "通过训练，使得正负样本数量均衡。一般用来减少实验结果的假阳性问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.在一个CNN网络中，计算整个数据集是不现实的，通常使用什么方法估计呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 最大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.以下哪个参数是learning rate(学习速率)?Weight decay(权值衰减量)?momentum(动量)?  \n",
    "$$ L(w) = \\frac{1}{N}\\sum_{i=0}^{N}f_w(X^{(i)})+\\lambda r(W)$$  \n",
    "$$ V_{i+1} = \\mu V_{t} - \\alpha \\nabla L(W_{i} )$$  \n",
    "$$ W_{i+1} = W_{i} + V_{i+1} $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝛼 是学习率\n",
    "𝜆 权值衰减量\n",
    "𝜇 是动量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.课上讲的深度学习三要素是哪三个(加入自己理解回答)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 特征提取: 根据业务数据设计特征值的结构\n",
    "2. 算法: 需要设计合理的算法,去学习数据的特征值.\n",
    "3. 预测模型: 用来实际预测未知的数据."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T03:17:19.177524Z",
     "start_time": "2018-10-26T03:17:19.175041Z"
    }
   },
   "source": [
    "### 17.传统方法selective search是如何生成目标框的?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "主要运用图像分割技术来产生目标框."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.Faster-RCNN中2k scores的2和4k coordinates的4分别是什么意思?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1个区域2个scores,所以k个区域是2k个scores.\n",
    "个区域4个coordinates,所以k个区域是4k个coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 19.简述RCNN(Region CNN)流程及Fast-RCNN与RCNN相比有什么区别?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region CNN流程:\n",
    "1.输入图像；\n",
    "2.利用 selective search 从下到上提取可能包含候选框的区域（大概2000个左右）；\n",
    "3. 因为选取的区域大小各不相同，所以要将每个候选框缩放成同一大小（为了适应卷积运算）；\n",
    "4. 输入到下一层的 CNN（卷积神经网络可以是 AlexNet、GoogleNet、VGG 等均可）进行统一的卷积运算，将 CNN 的输出作为特征；\n",
    "5. 将特征输入分类器 SVM 进行分类；\n",
    "6. 最后，使用回归模型来修正候选框的位置，对于每个类训练一个线性回归模型来判断候选框的位置是否完美，若不够完美则进行修正、优化、微调；\n",
    "在 R-CNN 中采用 softmax 做概率分布的输出。\n",
    "\n",
    "Fast-RCNN与RCNN的区别:\n",
    "1.在最后一个卷积层后面加入了 RoI 池化层；\n",
    "2.损失函数：采用多任务损失函数，将边框回归加入了 CNN 网络训练中，与分类任务合并，两个任务共享卷积特征，互相促进。（整个训练的过程是 end-to-end 的）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.写出目标检测的评价指标中Precision和Recall公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "混淆矩阵:\n",
    "    GroundTruth\\Predict\tTrue\tFalse\n",
    "       True\t             TP      FN\n",
    "       False             FP   TN\n",
    "TP：真正：正例预测为正  \n",
    "FP：假正：负例预测为正  \n",
    "FN：假负：正例预测为负  \n",
    "TN：真负：负例预测为负  \n",
    "衡量的是一个分类器分出来的正类的确是正类的概率 Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "衡量的是一个分类器能把所有的正类都找出来的能力 Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计20分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorboard.program import TensorBoard\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train[0].shape)\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    f = np.load(path)\n",
    "    x_train = f['x_train']\n",
    "    y_train = f['y_train']\n",
    "    x_test = f['x_test']\n",
    "    y_test = f['y_test']\n",
    "    f.close()\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print(\"x_test:\",x_test[2000:])\n",
    "\n",
    "print(input_shape)\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "print(x_train[0, :1, :2])\n",
    "\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"train samples:\", x_train.shape[0])\n",
    "print(\"test sampels:\", x_test.shape[0])\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train)\n",
    "print(\"true label is: \", np.where(y_test[:1][0] == 1)[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.1),\n",
    "              #               optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test[2000:], y_test[2000:])\n",
    "                    )\n",
    "\n",
    "score = model.evaluate(x_test[2000:], y_test[2000:], verbose=1)\n",
    "print(\"test accuracy:\", score[1])\n",
    "\n",
    "model.save(\"./mnist.h5\")\n",
    "\n",
    "model_mnist = keras.models.load_model(\"mnist.h5\")\n",
    "\n",
    "result = model_mnist.predict_classes(x_test[:1], batch_size=1, verbose=0)\n",
    "print(\"predict is: \", result)\n",
    "print(\"true label is: \", np.where(y_test[:1][0] == 1)[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
