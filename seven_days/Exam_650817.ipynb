{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Center><font color=red><b>考试题</b></font></Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注：先将试卷下载到本地,做完后进行上传,谢谢！\n",
    "* 试卷命名格式: Exam_学号.ipynb  例如：Exam_123456.ipynb\n",
    "* 试卷上传地址(请将自己的试卷存放到该地址)：http://47.93.208.249:9320/tree/0.Teacher/Online/Exam_students\n",
    "* 发布的试卷是只读模式，请下载或移动到上述地址后作答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学号(双击填写):650817"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>分数:100</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 简答题(4分/题 共100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.简述线性分类器的原理."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "线性分类器是一种通过特征的线性组合来分类的分类器。\n",
    "课程中用一副猫的图片，3行2列，行代表特征数量，列代表特征的种类。f = W . X+b，点乘。把列向量X通过矩阵W转化为种类向量。\n",
    "一张图像对应不同分类的得分，是通过使用内积来比较图像和模板，然后找到和哪个模板最相似。\n",
    "从这个角度来看，线性分类器就是在利用学习到的模板，针对图像做模板匹配。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.物体检测问题概述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "物体检测即目标检测，在图片里，用一个框标出目标（物体）的位置。\n",
    "其任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。\n",
    "由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.计算机视觉中，有哪几种基本任务？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "（1）分类，图片中物体的分类。\n",
    "（2）目标检测，分类 + 标框，详细见第 2 题的回答。\n",
    "（3）目标跟踪，在视频中对某一物体进行连续标识。\n",
    "（4）图像分割，语义分割、实例分割。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.常见物体检测算法列举"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "目前目标检测领域的深度学习方法主要分为两类：两阶段（Two Stages）的目标检测算法；一阶段（One Stage）目标检测算法。\n",
    "（1）两阶段（Two Stages）：首先由算法（algorithm）生成一系列作为样本的候选框，再通过卷积神经网络进行样本（Sample）分类。\n",
    "常见的算法有R-CNN、Fast R-CNN、Faster R-CNN等等。\n",
    "（2）一阶段（One Stage ）：不需要产生候选框，直接将目标框定位的问题转化为回归（Regression）问题处理(Process)。\n",
    "常见的算法有YOLO、SSD等等。\n",
    "（3）基于候选区域（Region Proposal）的，如R-CNN、SPP-net、Fast R-CNN、Faster R-CNN、R-FCN；\n",
    "（4）基于端到端（End-to-End），无需候选区域（Region Proposal）的，如YOLO、SSD。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.针对如下图片,我们需要调节哪些参数?为什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center class=\"half\">       \n",
    "    <img src=\"https://s3.ax1x.com/2021/01/21/shHjdx.jpg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1、增大学习速率\n",
    "一开始Loss下降的太慢了，500多次才开始下降。\n",
    "2、震荡比较大\n",
    "gradient不稳定，batch size 要调大，但是调大有代价，因为参数变多，需要更大的GPU内存，要量力而行，调到再大就报错就充分利用了。\n",
    "3、欠拟合\n",
    "训练的和验证的太像了，可能模型泛化能力不佳，是由于网络参数太多，还没喂饱，未能训练足够的情况。\n",
    "需要更多的训练数据，比如可以通过数据增强的方法（旋转、翻转、加噪声等）增加更多的数据。\n",
    "减少参数也是一个办法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.写出神经网络中常见的激励函数(至少三个)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "（1）sigmoid：1/(1+e^(-x))\n",
    "（2）ReLU：max(0,x)\n",
    "（3）Leaky ReLU\n",
    "x>=0：x\n",
    "x<0：x/a，a是一个比 1 大的数\n",
    "（4）tanh\n",
    "(e^x-e^(-x)) / e^x+e^(-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.请问图示中卷积模板功能?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center class=\"half\">       \n",
    "    <img src=\"https://s3.ax1x.com/2021/01/21/shbNfU.jpg\" width=\"40%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge detection，锐化，考虑了两个对角线的方向。加强中央，减弱周围，增强了与周围像素的对比度，从而使图像显得棱角分明、画面清晰，起到锐化图像的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、计算题(提示:参数共享，不考虑bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T06:36:15.614551Z",
     "start_time": "2019-10-08T06:36:15.609786Z"
    }
   },
   "source": [
    "* Example1: 200\\*200 image(灰度图), 40K hidden units  有多少个参数?\n",
    "* Example2: 200\\*200 image(灰度图), 40K hidden units, Filter size: 10\\*10 有多少个参数?\n",
    "* Example3: 200\\*200 image(灰度图), 100 Filter, Filter size:10\\*10  有多少参数?\n",
    "* Example4: 图像尺寸为[32\\*32\\*3], 卷积窗口大小为5\\*5, 卷积模板个数为1, 有多少参数?\n",
    "* Example5: 图像尺寸为[16\\*16\\*20], 卷积窗口大小为3\\*3, 卷积模板个数为10, 有多少参数?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "（1）200*200*40K\n",
    "（2）10*10*40K\n",
    "（3）10*10*100\n",
    "（4）5*5*3\n",
    "（5）3*3*10*20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.计算下图池化层(MaxPoolling)结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center class=\"half\">       \n",
    "    <img src=\"https://s3.ax1x.com/2021/01/21/shq9A0.jpg\" width=\"80%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    [6, 8],\n",
    "    [3, 4]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.什么是感受野?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seven老师正解：某一层特征图里的某个cell所对应的原图的区域大小。\n",
    "举例：11*11-->（5*5conv）-->7*7-->（7*7）-->1*1\n",
    "从1*1的像素倒推，最后的1*1来自上一层的 7*7 ，其conv是5*5，所以 7*7 的框要向四周扩展2个像素（padding=0），变为11*11。\n",
    "3个3*3的堆在一起，感受野是7*7。\n",
    "课程还总结了一个公式，这里略去不表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.简述Encode和Decode思想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "指的是 Encode-Decoder 模型\n",
    "（1）Encode\n",
    "接收输入（CNN，RNN等），并输出特征向量的网络。在语义分割中，就是用pooling池化层减小空间的维度。\n",
    "（2）decoder\n",
    "从encode中获取特征向量，输出与预期输出最近似的结果的网络。在语义分割中，逐渐恢复图像的细节信息和它的空间维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.什么是NMS（Non-maximum suppression 非极大值抑制）?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "在RCNN系列目标检测中，有一个重要的算法，用于消除一些冗余的bounding box，这就是non-maximum suppression算法。\n",
    "非极大值抑制,就是抑制不是极大值的元素,可以理解为局部最大搜索，这个局部代表的是一个邻域,邻域有两个参数可变,一是邻域的维数,\n",
    "二是邻域的大小。\n",
    "非极大值抑制可以帮助抑制除局部最大值之外的所有梯度值(通过将它们设置为0) ,使其指示具有最强烈的强度值变化的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.什么是Hard Mining？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "主要指以下两类：\n",
    "难分正样本(hard positives)：错分成负样本的正样本，也可以是训练过程中损失最高的正样本\n",
    "难分负样本(hard negatives)：错分成正样本的负样本，也可以是训练过程中损失最高的负样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.在一个CNN网络中，计算整个数据集是不现实的，通常使用什么方法估计呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "可以用Mini-batching，训练数据集的一小部分，而不是整个训练集。它使用的内存较小、不能同时训练整个数据集的电脑也可以训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.以下哪个参数是learning rate(学习速率)?Weight decay(权值衰减量)?momentum(动量)?  \n",
    "$$ L(w) = \\frac{1}{N}\\sum_{i=0}^{N}f_w(X^{(i)})+\\lambda r(W)$$  \n",
    "$$ V_{i+1} = \\mu V_{t} - \\alpha \\nabla L(W_{i} )$$  \n",
    "$$ W_{i+1} = W_{i} + V_{i+1} $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning rate 是 a; Weight decay 是 lamda; momentum 是 u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.课上讲的深度学习三要素是哪三个(加入自己理解回答)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.数据：数据的数量和质量很重要，数据的质量决定了最终结果的上限，因为都是根据这些数据源计算出来的。\n",
    "2.模型：算法与模型的选择与调优是为了逼近最终结果的上限。\n",
    "3.算力：之前就有不错的算法提出，但受限于算力，效果不理想，近几年算力增强，网络层数越来越多，可尝试更多的可能性，也产生更好地结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T03:17:19.177524Z",
     "start_time": "2018-10-26T03:17:19.175041Z"
    }
   },
   "source": [
    "### 17.传统方法selective search是如何生成目标框的?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "选择性算法使用的是按层次合并算法（Hierarchical Grouping），基本思路如下：\n",
    "首先，使用论文“Efficient Graph-Based Image Segmentation”中的方法生成一些起始的小区域，之后使用贪心算法将区域归并到一起：\n",
    "先计算所有临近区域间的相似度（通过颜色，纹理，吻合度，大小等相似度），将最相似的两个区域归并，\n",
    "然后重新计算临近区域间的相似度，归并相似区域直至整幅图像成为一个区域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.Faster-RCNN中2k scores的2和4k coordinates的4分别是什么意思?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2k中的2是指：每一个anchor对应k个候选框，每一个候选框有 2 个取值（有和无，概率大小）\n",
    "4k中的4是指：[x, y, w, h]对应4个偏移量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 19.简述RCNN(Region CNN)流程及Fast-RCNN与RCNN相比有什么区别?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1、RCNN流程大概有4个步骤：\n",
    "（1）一张图生成1k-2k个候选区域（使用后selective search方法）\n",
    "（2）对每个候选区域使用深度网络提取特征\n",
    "（3）特征送入每一类SVM分类器，判别是否属于该类\n",
    "（4）使用回归器精细修正候选框位置\n",
    "2、Fast-RCNN 与 RCNN的区别\n",
    "主要是RCNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。\n",
    "大缺点：由于每一个候选框都要独自经过CNN，很耗时！\n",
    "解决方法：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征。\n",
    "原来的方法：许多候选框（比如两千个）-->CNN-->得到每个候选框的特征-->分类+回归\n",
    "现在的方法：一张完整图片-->CNN-->得到每张候选框的特征-->分类+回归\n",
    "所以容易看见，Fast RCNN相对于RCNN的提速原因就在于：不过不像RCNN把每个候选区域给深度网络提特征，而是整张图提一次特征，\n",
    "再把候选框映射到conv5上，而SPP只需要计算一次特征，剩下的只需要在conv5层上操作就可以了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.写出目标检测的评价指标中Precision和Recall公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = tp / (tp + fp)\n",
    "Recall = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:4</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计20分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Score:20</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 这是一个能用的模型，下面是模型训练 ===================================================================================\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' #使用GPU\n",
    " \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "X_train = X_train / 255 #归一化\n",
    "X_test = X_test / 255\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10) #label onehot化\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    " \n",
    "def lenet():\n",
    "    model = Sequential()\n",
    "    #第一层卷积\n",
    "    model.add(Conv2D(input_shape=(28, 28, 1), kernel_size=(5, 5), filters=20, activation='relu')) #filters为输出通道数\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='same'))\n",
    "    #第二层卷积\n",
    "    model.add(Conv2D(kernel_size=(5, 5), filters=50,  activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='same'))\n",
    " \n",
    "    model.add(Flatten()) #进入全连接层fc之前，要展成一维数组\n",
    "    model.add(Dense(500, activation='relu')) #全连接层fc1\n",
    "    model.add(Dense(10, activation='softmax')) #全连接层fc2\n",
    "    sgd = SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True) #确定优化器\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) #模型编译\n",
    "    return model #最后返回模型\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    model = lenet() #加载lenet模型\n",
    "    print('Training')\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=32,validation_split=0.2) #训练模型\n",
    "    # validation_split=0.2表示，每五个训练集中拿一个出来当验证集\n",
    " \n",
    "    print('\\nTesting')\n",
    "    text_loss, text_accuracy = model.evaluate(X_test, y_test) #测试模型\n",
    " \n",
    "    print('\\ntest loss: ', text_loss)\n",
    "    print('\\ntest accuracy: ', text_accuracy)\n",
    " \n",
    "    #keras画图\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1,len(acc)+1)\n",
    " \n",
    "    plt.plot(epochs,acc,'bo',label='trainning acc')\n",
    "    plt.plot(epochs,loss,'b',label='training loss')\n",
    "    plt.plot(epochs,val_acc,'ro',label='val_acc')\n",
    "    plt.plot(epochs,val_loss,'r',label='val_loss')\n",
    " \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    model.save('lenet.h5')\n",
    "\n",
    "# 下面是测试 =================================================================================================================\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "print(\"Using loaded model to predict...\")\n",
    "load_model = load_model(\"./lenet.h5\")\n",
    "img = cv2.imread('3.png',cv2.IMREAD_GRAYSCALE)\n",
    "img = img.reshape(-1, 28, 28, 1)\n",
    "img = img/255\n",
    "predicted = load_model.predict(img)\n",
    "print(predicted)\n",
    "predicted = np.argmax(predicted)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
