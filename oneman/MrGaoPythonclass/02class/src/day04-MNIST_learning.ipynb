{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\ProgramData\\Anaconda3\\Scripts\\win\n",
    "\n",
    "    py38环境启动失败报错解决：ImportError: DLL load failed while importing win32api: 找不到指定的模块\n",
    "    首先，找到文件pywin32_postinstall.py，路径在[Path to Anaconda3]\\Scripts\\\n",
    "    然后执行：python [Path to Anaconda3]\\Scripts\\pywin32_postinstall.py -install 即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片预处理和数据结构的理解\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "#图片在计算机茨城县的状态/方式\n",
    "img = Image.open(\"../data/Duanwu Festival.jpg\")\n",
    "to_array = np.array(img)\n",
    "print(to_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_array.shape 表示数组行列大小（高h=行，宽w=列）\n",
    "\n",
    "### reshape转换前后的维度乘积要一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6220800,)\n",
      "[250 251 245 ...  40  39  35]\n"
     ]
    }
   ],
   "source": [
    "to_array1 = np.array(img).reshape(1080*1920*3)\n",
    "print(to_array1.shape)\n",
    "print(to_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6220800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "1080*1920*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用全连接层（Fully Connected）搭建网络\n",
    "    dropout处理过度学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras #keras整框架导入\n",
    "from keras.datasets import mnist #数据集\n",
    "import matplotlib.pyplot as plt #matplotlib 用于打印输出图或图表\n",
    "from keras.layers import Dense, Dropout #神经网络层导入\n",
    "from keras.models import Sequential #网络建设模式Sequential序列模型和Model函数模型\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载官方mnist数据集\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "#（训练样本，训练样本的标签）（测试样本，测试样本的标签）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1\n",
    "print(y_train[index])\n",
    "plt.imshow(x_train[index])\n",
    "plt.title('Label Number: '+str(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一部数据的预先处理之归一化 即将0-255之间的数据 压缩到0-1之间\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "#根据网络要求改变数组输入的shape\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签转one-hot-encoding\n",
    "y_train = keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#搭建网络结构 - 全连接层\n",
    "model = Sequential() #实例化\n",
    "#像模型中添加层Dense层为全连接层\n",
    "model.add(Dense(units=128, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.25)) #dropout是一个层，防止网络过度学习，比如学习了100个就保留一部分\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型编译-设置模型的损失loss、优化器optimizier\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0130 - val_accuracy: 0.9960\n",
      "Epoch 2/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0144 - val_accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0209 - val_accuracy: 0.9933\n",
      "Epoch 4/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0211 - val_accuracy: 0.9923\n",
      "Epoch 5/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 6/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0336 - val_accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0387 - val_accuracy: 0.9875\n",
      "Epoch 8/10\n",
      "844/844 [==============================] - 3s 3ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0405 - val_accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0427 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0360 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x246b68c7dc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = 64, #60000/63=938\n",
    "    epochs = 10,     #训练轮数\n",
    "    \n",
    "    validation_split=0.1 #拿出10%训练样本作为验证样本，随着训练就开始验证\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用测试集测试效果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9807\n",
      "0.10068202018737793 0.9807000160217285\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/mnistTrain.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 加载DIY样本并进行预处理\n",
    "img_open = Image.open('../data/3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "img_to_array = np.array(img_open).reshape(1,784,)/255.0\n",
    "print(img_to_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../output/mnistTrain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1866647e-07, 6.0129300e-05, 8.2924409e-04, 9.5674980e-01,\n",
       "        9.9961499e-06, 3.2953180e-06, 1.3889957e-09, 8.4316153e-03,\n",
       "        3.8246217e-03, 3.0091064e-02]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(img_to_array)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Pred = [result.argmax() for result in prediction][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(Final_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0概率 0.00%\n",
      "1概率 0.01%\n",
      "2概率 0.08%\n",
      "3概率 95.67%\n",
      "4概率 0.00%\n",
      "5概率 0.00%\n",
      "6概率 0.00%\n",
      "7概率 0.84%\n",
      "8概率 0.38%\n",
      "9概率 3.01%\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in prediction[0]:\n",
    "    percent = \"%.2f%%\"%(i*100)\n",
    "    print(str(counter)+\"概率\",percent)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
